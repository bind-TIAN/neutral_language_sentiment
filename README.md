# neutral_language_sentiment
---
## 初步方案
---
### 情感词典方式
*    采用ChnSentiCorp_htl_ba_2000数据集，从知网等媒介找相关情感词典构成词典库。合理构建出积极词典、消极词典、程度词典、否定词典。
*    对文本去噪得到清洗数据集，然后进行词语相似度判断。
*    清洗数据集中每个词性的词都进行相似度判断判断，我们这里令积极词典叫正向词典， 消极词典叫负向词典。对于正向清洗数据集，需要优先往正向词典中判断，若阈值小于0.9， 则接着往负向词典判断，依次判断其他词典库。对于负向清洗数据集，则优先往负向情感词 典中判断。据我们所知，阈值去0.9比较合适，以上基于情感分析得出每条评论抽象文件， 进而得出所有评论的抽象数据集。
*    将清洗后的文本数据集划分成训练集和数据集，然后根据得到的抽象数据集进行机器学习，学习过程中若出现正向词，则新加入到原来正向词典中，其他词如是处理。根据情感词前后词性类型判断，比如积极词语前面若是程度词，则相应权值加倍，若是消极词，则相应减去一定权值，从而把每条评论都计算出了一个最终值。若该值为正则是正向的否则是负向的。
*    根据训练模型构建KNN、Kmeans、贝叶斯算法，对测试数据集进行预测。在此过程中， 训练集得到的结果，使用绘图工具表示，采用KNN欧拉回路方法，取合理K值对测试数据归类。

### SVM方式
---
*    根据ChnSentiCorp_htl_ba_2000评论文本数据进行清洗。
*    采用train_test_split对数据集进行“二八”随机划分，即80%训练集，20%测试集。
*    将划分好的训练集和测试集采用word2vec训练出模型。据我们所知，语料库采用CBOW 模型合适，且迭代次数为100次较好。对one-hot向量规定了300大小，并在文本中前后查看5 个单词比较合适，另外用的是普遍采用的softmax回归。得出训练模型和测试模型。
*    根据训练集和测试集中的每条评论中每个词向量求均值，得出该评论的语句向量。加入 到列表中用于接下来的预测。
*    反复训练模型，直到比较优的时候开始预测，这个过程中使用预先分好的测试集对模型 进行评判打分从而筛选出合理模型。然后直接对新输入的测试样本进行预测操作。

## 两个模型的实施方案的难点
---
### 对于情感词典方式
---
*    python库函数对词语间相似度判断不明确，造成反义词误判为近义词。影响构建好的情 感词词典。阈值定义需要多次尝试。文本中双重否定，以及不紧挨着的否定，在判断中都视 为同一种，是造成误判的原因之一。
*    以正向、负向相似度权值作为坐标得出有监督学习点集合，根据KNN算法进行学习。不清楚程度词和否定词对坐标的影响强弱。另外Kmeans进行无监督聚类能够得出线性可分 曲线函数表达式，贝叶斯算法进行预测也能够得出较为准确的预测。

### 对于SVM方式
---
*    word2vec中提供的一些参数需要多次训练得出，一些参数需要人工确定。
*    根据每个词向量相加求均值得出该评论语句的向量作为分析标准。

## 环境
*    pycharm(python.3.7)
*    windows10

## 数据集
*    修改后的ChnSentiCorp_htl_ba_10000，包含正向负向各11000条评论文本
